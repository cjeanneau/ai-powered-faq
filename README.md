# ğŸ¤– Assistant FAQ Intelligent - CollectivitÃ© Territoriale

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)](https://fastapi.tiangolo.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸ“‹ Description

API REST d'assistance FAQ pour la CommunautÃ© de Communes Val de Loire NumÃ©rique. L'assistant rÃ©pond aux questions des citoyens sur les dÃ©marches administratives en s'appuyant sur une base de connaissances structurÃ©e.

## ğŸ¯ Vue d'ensemble du projet

```mermaid
flowchart TB
    subgraph INPUT["ğŸ“¥ EntrÃ©e"]
        Q[/"â“ Question utilisateur"/]
        FAQ[("ğŸ“š Base FAQ60-80 Q/R")]
    end

    subgraph STRATEGIES["ğŸ”„ Benchmark des 3 StratÃ©gies"]
        direction TB
        
        subgraph SA["StratÃ©gie A : LLM Seul"]
            A1["Prompt systÃ¨me contextualisÃ©"] --> A2["ğŸ¤– LLM Mistral-7B"]
            A2 --> A3["RÃ©ponse gÃ©nÃ©rÃ©e"]
        end
        
        subgraph SB["StratÃ©gie B : RAG SimplifiÃ©"]
            B1["ğŸ” Recherche sÃ©mantique"] --> B2["ğŸ“„ Top-K FAQ pertinentes"]
            B2 --> B3["ğŸ¤– LLM +Contexte"]
            B3 --> B4["RÃ©ponse augmentÃ©e"]
        end
        
        subgraph SC["StratÃ©gie C : Q&A Extractif"]
            C1["ğŸ” Recherche sÃ©mantique"] --> C2["ğŸ“„ Top-K FAQ pertinentes"]
            C2 --> C3["ğŸ¯ ModÃ¨le Q&A RoBERTa"]
            C3 --> C4["RÃ©ponse extraite"]
        end
    end

    subgraph EVAL["ğŸ“Š Ã‰valuation"]
        E1["Golden Set25-30 questions"]
        E2["MÃ©triques :â€¢ Exactitude 30%â€¢ Pertinence 20%â€¢ Hallucinations 20%â€¢ Latence 15%â€¢ ComplexitÃ© 15%"]
        E3["ğŸ“ˆ Rapport Benchmark"]
    end

    subgraph API["ğŸš€ API Production"]
        F1["FastAPI/api/v1/ask"]
        F2["StratÃ©gie retenue"]
        F3["ğŸ“‹ Logs & Monitoring"]
    end

    subgraph CICD["âš™ï¸ CI/CD"]
        G1["pytest"]
        G2["GitHub Actions"]
        G3["Docker"]
    end

    Q --> SA
    Q --> SB
    Q --> SC
    FAQ --> B1
    FAQ --> C1

    A3 --> E1
    B4 --> E1
    C4 --> E1
    E1 --> E2
    E2 --> E3

    E3 -->|"Recommandation"| F2
    F2 --> F1
    F1 --> F3

    F1 --> G1
    G1 --> G2
    G2 --> G3

    style SA fill:#ffebee,stroke:#c62828
    style SB fill:#e3f2fd,stroke:#1565c0
    style SC fill:#e8f5e9,stroke:#2e7d32
    style EVAL fill:#fff3e0,stroke:#ef6c00
    style API fill:#f3e5f5,stroke:#7b1fa2
    style CICD fill:#eceff1,stroke:#546e7a
```

### ğŸ”€ Comparaison des StratÃ©gies - Exemple

```mermaid
flowchart LR
    subgraph QUESTION["Question"]
        Q["Comment obtenir un acte de naissance ?"]
    end

    subgraph STRAT_A["ğŸ…°ï¸ LLM Seul"]
        direction TB
        SA1["Prompt + Question"]
        SA2["LLM gÃ©nÃ¨re depuis ses connaissances"]
        SA1 --> SA2
    end

    subgraph STRAT_B["ğŸ…±ï¸ RAG"]
        direction TB
        SB1["Encode question en embedding"]
        SB2["Recherche FAQ similaires"]
        SB3["LLM gÃ©nÃ¨re avec contexte FAQ"]
        SB1 --> SB2 --> SB3
    end

    subgraph STRAT_C["ğŸ…² Q&A Extractif"]
        direction TB
        SC1["Encode question en embedding"]
        SC2["Recherche FAQ similaires"]
        SC3["ModÃ¨le extrait rÃ©ponse du texte"]
        SC1 --> SC2 --> SC3
    end

    Q --> SA1
    Q --> SB1
    Q --> SC1

    SA2 --> RA["ğŸ’¬ RÃ©ponse potentiellement hallucinÃ©e"]
    SB3 --> RB["ğŸ’¬ RÃ©ponse contextualisÃ©e"]
    SC3 --> RC["ğŸ’¬ RÃ©ponse exacte extraite"]

    style STRAT_A fill:#ffebee
    style STRAT_B fill:#e3f2fd
    style STRAT_C fill:#e8f5e9
```

## ğŸ—ï¸ Architecture du projet

```txt
.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ strategies/          # Les 3 stratÃ©gies de rÃ©ponse
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py          # Classe abstraite commune
â”‚   â”‚   â”œâ”€â”€ strategy_a_llm.py
â”‚   â”‚   â”œâ”€â”€ strategy_b_rag.py
â”‚   â”‚   â””â”€â”€ strategy_c_qa.py
â”‚   â”œâ”€â”€ api/                 # API FastAPI
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ routes.py
â”‚   â”‚   â””â”€â”€ models.py
â”‚   â”œâ”€â”€ utils/               # Utilitaires
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ embeddings.py
â”‚   â”‚   â”œâ”€â”€ llm_client.py
â”‚   â”‚   â””â”€â”€ logging_config.py
â”‚   â””â”€â”€ tests/               # Tests
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ test_strategies.py
â”‚       â”œâ”€â”€ test_api.py
â”‚       â””â”€â”€ test_regression.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ faq_base.json        # Base FAQ fournie
â”‚   â”œâ”€â”€ golden_set.json      # Jeu de test fourni
â”‚   â””â”€â”€ grille_evaluation.csv
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ BRIEF_PROJET.md
â”‚   â”œâ”€â”€ NOTE_CADRAGE.md
â”‚   â”œâ”€â”€ RAPPORT_VEILLE.md
â”‚   â””â”€â”€ RAPPORT_BENCHMARK.md
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_benchmark.py
â”‚   â””â”€â”€ evaluate_results.py
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

## ğŸš€ Installation

### PrÃ©requis

- Python 3.10 ou supÃ©rieur
- pip ou conda
- Git
- (Optionnel) Docker

### Installation locale

1. **Cloner le repository**
```bash
git clone <votre-repo>
cd projet-faq-intelligent
```

2. **CrÃ©er un environnement virtuel**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows
```

3. **Installer les dÃ©pendances**
```bash
pip install -r requirements.txt
```

4. **Configurer les variables d'environnement**
```bash
cp .env.example .env
# Ã‰diter .env avec votre token HuggingFace si nÃ©cessaire
```

5. **VÃ©rifier l'installation**
```bash
python -c "import sentence_transformers; print('OK')"
```

### Installation Docker (optionnel)

```bash
docker-compose up --build
```

## ğŸ“– Utilisation

### Lancer l'API

```bash
uvicorn src.api.main:app --reload --port 8000
```

L'API est accessible sur `http://localhost:8000`

Documentation interactive : `http://localhost:8000/docs`

### Tester une question

```bash
curl -X POST "http://localhost:8000/api/v1/ask" \
  -H "Content-Type: application/json" \
  -d '{"question": "Comment obtenir un acte de naissance ?"}'
```

### Lancer les tests

```bash
# Tous les tests
pytest

# Avec couverture
pytest --cov=src --cov-report=html

# Tests de non-rÃ©gression uniquement
pytest src/tests/test_regression.py -v
```

### ExÃ©cuter le benchmark

```bash
python scripts/run_benchmark.py
```

## ğŸ”§ Configuration

### Variables d'environnement

| Variable | Description | DÃ©faut |
|----------|-------------|--------|
| `HF_API_TOKEN` | Token HuggingFace (optionnel pour modÃ¨les publics) | - |
| `LLM_MODEL` | ModÃ¨le LLM Ã  utiliser | `mistralai/Mistral-7B-Instruct-v0.2` |
| `EMBEDDING_MODEL` | ModÃ¨le d'embeddings | `all-MiniLM-L6-v2` |
| `LOG_LEVEL` | Niveau de logging | `INFO` |
| `CONFIDENCE_THRESHOLD` | Seuil de confiance minimal | `0.5` |

## ğŸ“Š MÃ©triques exposÃ©es

L'endpoint `/metrics` expose :

- `faq_requests_total` : Nombre total de requÃªtes
- `faq_response_latency_seconds` : Latence moyenne
- `faq_low_confidence_total` : Nombre de rÃ©ponses "je ne sais pas"

## ğŸ“ Documentation

- [Brief projet](docs/BRIEF_PROJET.md)
- [Note de cadrage](docs/NOTE_CADRAGE.md)
- [Rapport de veille](docs/RAPPORT_VEILLE.md)
- [Rapport de benchmark](docs/RAPPORT_BENCHMARK.md)

## ğŸ§ª Tests

Le projet inclut :

- **Tests unitaires** : Validation des fonctions individuelles
- **Tests d'intÃ©gration** : Validation des endpoints API
- **Tests de non-rÃ©gression** : Validation sur le golden set avec seuil de qualitÃ©

## ğŸ‘¤ Auteur

RÃ©mi Julien

## ğŸ“„ Licence

MIT
