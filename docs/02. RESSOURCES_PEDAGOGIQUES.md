# ğŸ“š Ressources PÃ©dagogiques - Projet FAQ Intelligent

Ce document recense les ressources essentielles pour mener Ã  bien le projet. Consultez-les selon vos besoins et le planning proposÃ©.

---

## ğŸ¯ Parcours d'Apprentissage RecommandÃ©

| Phase | Jours | Focus | Ressources prioritaires |
|-------|-------|-------|------------------------|
| Cadrage & Veille | J1-J2 | Comprendre RAG, embeddings, Q&A | Sections 1, 2, 3 |
| ImplÃ©mentation | J3-J5 | Coder les 3 stratÃ©gies | Sections 2, 3, 4 |
| API | J7 | DÃ©velopper l'API REST | Section 5 |
| Tests & CI/CD | J8-J9 | Industrialiser | Section 6 |

---

## 1. ğŸ¤— HuggingFace - API Inference

L'API Inference de HuggingFace permet d'utiliser des modÃ¨les de ML sans infrastructure locale.

### Documentation officielle

| Ressource | Description | Lien |
|-----------|-------------|------|
| **Serverless Inference API** | Documentation principale de l'API gratuite | [huggingface.co/docs/api-inference](https://huggingface.co/docs/api-inference/index) |
| **Getting Started** | Guide de dÃ©marrage rapide | [huggingface.co/inference/get-started](https://huggingface.co/inference/get-started) |
| **Inference Providers** | Guide des providers d'infÃ©rence unifiÃ©s | [huggingface.co/docs/inference-providers](https://huggingface.co/docs/inference-providers/en/index) |
| **API Reference - Tasks** | RÃ©fÃ©rence des tÃ¢ches (chat, embeddings, Q&A...) | [huggingface.co/docs/inference-providers/tasks](https://huggingface.co/docs/inference-providers/en/tasks/index) |

### Tutoriels pratiques

| Ressource | Description | Lien |
|-----------|-------------|------|
| **Serverless Inference Cookbook** | Notebook avec exemples complets | [huggingface.co/learn/cookbook](https://huggingface.co/learn/cookbook/en/enterprise_hub_serverless_inference_api) |
| **How to Use HuggingFace API** | Tutoriel pas Ã  pas (GeeksforGeeks) | [geeksforgeeks.org](https://www.geeksforgeeks.org/deep-learning/how-to-use-hugging-face-api/) |

### âš ï¸ Important : API Chat vs Text Generation

Les modÃ¨les comme **Mistral** utilisent l'API **chat** (conversational) et non `text_generation`. Utilisez `chat_completion()` :

```python
from huggingface_hub import InferenceClient

client = InferenceClient(token="votre_token")

# âœ… Bonne mÃ©thode : chat_completion (pour Mistral, Zephyr, etc.)
messages = [
    {"role": "system", "content": "Tu es un assistant utile."},
    {"role": "user", "content": "Bonjour, comment puis-je vous aider ?"}
]

response = client.chat_completion(
    model="mistralai/Mistral-7B-Instruct-v0.2",
    messages=messages,
    max_tokens=100
)

print(response.choices[0].message.content)
```

> âš ï¸ **Ne pas utiliser** `text_generation()` avec les modÃ¨les Mistral - cela provoquera une erreur "Model not supported for task text-generation".

---

## 2. ğŸ” Sentence-Transformers et Recherche SÃ©mantique

Les sentence-transformers convertissent du texte en vecteurs (embeddings) pour la recherche sÃ©mantique.

### Documentation officielle

| Ressource | Description | Lien |
|-----------|-------------|------|
| **GitHub officiel** | Repository avec documentation complÃ¨te | [github.com/UKPLab/sentence-transformers](https://github.com/UKPLab/sentence-transformers) |
| **Semantic Search Guide** | Guide officiel de la recherche sÃ©mantique | [sbert.net/semantic-search](https://www.sbert.net/examples/sentence_transformer/applications/semantic-search/README.html) |
| **HuggingFace Hub** | Tous les modÃ¨les sentence-transformers | [huggingface.co/sentence-transformers](https://huggingface.co/sentence-transformers) |

### ModÃ¨les recommandÃ©s

| ModÃ¨le | Dimensions | Vitesse | Usage |
|--------|------------|---------|-------|
| **all-MiniLM-L6-v2** | 384 | âš¡ Rapide | RecommandÃ© pour ce projet |
| all-mpnet-base-v2 | 768 | Moyen | Plus prÃ©cis, plus lent |
| paraphrase-multilingual-MiniLM-L12-v2 | 384 | Moyen | Multilingue |

**Model Card all-MiniLM-L6-v2** : [huggingface.co/sentence-transformers/all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)

### Exemple de code minimal

```python
from sentence_transformers import SentenceTransformer, util

# Charger le modÃ¨le
model = SentenceTransformer('all-MiniLM-L6-v2')

# Encoder des phrases
corpus = ["Comment obtenir un acte de naissance ?", "OÃ¹ dÃ©poser mes dÃ©chets verts ?"]
corpus_embeddings = model.encode(corpus, convert_to_tensor=True)

# Recherche sÃ©mantique
query = "Je voudrais un extrait de naissance"
query_embedding = model.encode(query, convert_to_tensor=True)

# Calculer les similaritÃ©s
similarities = util.cos_sim(query_embedding, corpus_embeddings)
print(similarities)  # La premiÃ¨re phrase sera la plus similaire
```

### Tutoriels complÃ©mentaires

| Ressource | Description | Lien |
|-----------|-------------|------|
| **Semantic Search Tutorial** | Tutoriel pratique FAQ (DZone) | [dzone.com/articles/sentence-transformers-semantic-search-tutorial](https://dzone.com/articles/sentence-transformers-semantic-search-tutorial) |
| **Step-by-Step Guide** | Guide dÃ©taillÃ© avec visualisations (Medium) | [medium.com/@hassanqureshi700](https://medium.com/@hassanqureshi700/a-step-by-step-guide-to-similarity-and-semantic-search-using-sentence-transformers-7091723a7bf9) |

---

## 3. ğŸ§  RAG (Retrieval-Augmented Generation)

Le RAG combine recherche d'information et gÃ©nÃ©ration pour des rÃ©ponses plus prÃ©cises.

### Comprendre le concept

| Ressource | Description | Lien |
|-----------|-------------|------|
| **What is RAG? (AWS)** | Introduction claire et complÃ¨te | [aws.amazon.com/what-is/retrieval-augmented-generation](https://aws.amazon.com/what-is/retrieval-augmented-generation/) |
| **Introduction to RAG (Weaviate)** | Article dÃ©taillÃ© avec architecture | [weaviate.io/blog/introduction-to-rag](https://weaviate.io/blog/introduction-to-rag) |
| **RAG Explained (Pinecone)** | Guide pratique avec exemples de prompts | [pinecone.io/learn/retrieval-augmented-generation](https://www.pinecone.io/learn/retrieval-augmented-generation/) |

### Architecture RAG simplifiÃ©e

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Question   â”‚â”€â”€â”€â”€â–¶â”‚  Recherche   â”‚â”€â”€â”€â”€â–¶â”‚  Contexte   â”‚
â”‚ utilisateur â”‚     â”‚  sÃ©mantique  â”‚     â”‚  rÃ©cupÃ©rÃ©   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
                    â”‚   RÃ©ponse    â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚   gÃ©nÃ©rÃ©e    â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â—€â”€â”€â”€â”€â”‚     LLM      â”‚
                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Exemple de code RAG simplifiÃ©

```python
from sentence_transformers import SentenceTransformer, util
from huggingface_hub import InferenceClient

# 1. Recherche sÃ©mantique
embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
faq_embeddings = embedding_model.encode(faq_texts, convert_to_tensor=True)

question = "Comment obtenir un acte de naissance ?"
q_emb = embedding_model.encode(question, convert_to_tensor=True)
similarities = util.cos_sim(q_emb, faq_embeddings)[0]
top_indices = similarities.argsort(descending=True)[:3]

# 2. Construction du contexte
context = "\n".join([faq_list[i]["answer"] for i in top_indices])

# 3. GÃ©nÃ©ration avec LLM
client = InferenceClient(token="votre_token")
messages = [
    {"role": "system", "content": "RÃ©ponds en te basant sur le contexte fourni."},
    {"role": "user", "content": f"Contexte:\n{context}\n\nQuestion: {question}"}
]
response = client.chat_completion(
    model="mistralai/Mistral-7B-Instruct-v0.2",
    messages=messages,
    max_tokens=300
)
print(response.choices[0].message.content)
```

### Ressources avancÃ©es

| Ressource | Description | Lien |
|-----------|-------------|------|
| **RAG for LLMs** | Techniques avancÃ©es (Prompt Engineering Guide) | [promptingguide.ai/research/rag](https://www.promptingguide.ai/research/rag) |
| **Introduction to RAG (Coursera)** | Projet guidÃ© 2h | [coursera.org/projects/introduction-to-rag](https://www.coursera.org/projects/introduction-to-rag) |

---

## 4. â“ Question-Answering Extractif

Le Q&A extractif extrait directement la rÃ©ponse d'un contexte donnÃ©.

### Documentation HuggingFace

| Ressource | Description | Lien |
|-----------|-------------|------|
| **Task: Question Answering** | Page de tÃ¢che avec dÃ©mo interactive | [huggingface.co/tasks/question-answering](https://huggingface.co/tasks/question-answering) |
| **Q&A Tutorial** | Tutoriel complet fine-tuning sur SQuAD | [huggingface.co/docs/transformers/tasks/question_answering](https://huggingface.co/docs/transformers/tasks/question_answering) |
| **HuggingFace Course - Chapter 7** | Chapitre gratuit sur le Q&A | [huggingface.co/course/chapter7/7](https://huggingface.co/course/chapter7/7) |

### ModÃ¨les recommandÃ©s

| ModÃ¨le | Langue | Performance | Lien |
|--------|--------|-------------|------|
| **deepset/roberta-base-squad2** | Anglais | F1: 82.9% | [huggingface.co/deepset/roberta-base-squad2](https://huggingface.co/deepset/roberta-base-squad2) |
| etalab-ia/camembert-base-squadFR-fquad-piaf | FranÃ§ais | Bon | [huggingface.co/etalab-ia/camembert-base-squadFR-fquad-piaf](https://huggingface.co/etalab-ia/camembert-base-squadFR-fquad-piaf) |

### Exemple de code minimal

```python
from transformers import pipeline

# Charger le pipeline Q&A
qa_pipeline = pipeline("question-answering", model="deepset/roberta-base-squad2")

# Poser une question sur un contexte
result = qa_pipeline(
    question="Quel est le dÃ©lai pour obtenir un acte de naissance ?",
    context="Pour obtenir un acte de naissance, le dÃ©lai est de 5 Ã  10 jours ouvrÃ©s."
)

print(result)
# {'answer': '5 Ã  10 jours ouvrÃ©s', 'score': 0.95, 'start': 52, 'end': 70}
```

---

## 5. ğŸš€ FastAPI - DÃ©veloppement d'API REST

FastAPI est un framework Python moderne pour crÃ©er des APIs performantes.

### Documentation officielle

| Ressource | Description | Lien |
|-----------|-------------|------|
| **FastAPI Documentation** | Documentation complÃ¨te officielle | [fastapi.tiangolo.com](https://fastapi.tiangolo.com/) |
| **Tutorial - User Guide** | Tutoriel pas Ã  pas | [fastapi.tiangolo.com/tutorial](https://fastapi.tiangolo.com/tutorial/) |
| **First Steps** | Premiers pas avec FastAPI | [fastapi.tiangolo.com/tutorial/first-steps](https://fastapi.tiangolo.com/tutorial/first-steps/) |

### Tutoriels complÃ©mentaires

| Ressource | Description | Lien |
|-----------|-------------|------|
| **FastAPI Tutorial (GeeksforGeeks)** | Tutoriel complet | [geeksforgeeks.org/fastapi-tutorial](https://www.geeksforgeeks.org/python/fastapi-tutorial/) |
| **Python REST APIs (Real Python)** | Tutoriel approfondi | [realpython.com/fastapi-python-web-apis](https://realpython.com/fastapi-python-web-apis/) |
| **FastAPI for ML (KDnuggets)** | OrientÃ© Data Science | [kdnuggets.com/fastapi-tutorial](https://www.kdnuggets.com/fastapi-tutorial-build-apis-with-python-in-minutes) |

### Exemple de code minimal

```python
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

class Question(BaseModel):
    question: str

class Answer(BaseModel):
    answer: str
    confidence: float

@app.post("/ask", response_model=Answer)
async def ask_question(q: Question):
    # Logique de rÃ©ponse ici
    return Answer(answer="RÃ©ponse gÃ©nÃ©rÃ©e", confidence=0.85)

# Lancer avec : uvicorn main:app --reload
```

### Points clÃ©s FastAPI

- **Documentation automatique** : Swagger UI sur `/docs`, ReDoc sur `/redoc`
- **Validation automatique** : Via Pydantic models
- **Async/await** : Support natif de l'asynchrone
- **Type hints** : AutocomplÃ©tion IDE et validation

---

## 6. ğŸ§ª Tests et CI/CD

### pytest

| Ressource | Description | Lien |
|-----------|-------------|------|
| **pytest Documentation** | Documentation officielle | [docs.pytest.org](https://docs.pytest.org/) |
| **Testing FastAPI** | Tests d'API avec TestClient | [fastapi.tiangolo.com/tutorial/testing](https://fastapi.tiangolo.com/tutorial/testing/) |

### Exemple de test

```python
from fastapi.testclient import TestClient
from main import app

client = TestClient(app)

def test_ask_question():
    response = client.post(
        "/ask",
        json={"question": "Comment obtenir un acte de naissance ?"}
    )
    assert response.status_code == 200
    assert "answer" in response.json()
```

### GitHub Actions

| Ressource | Description | Lien |
|-----------|-------------|------|
| **GitHub Actions Docs** | Documentation officielle | [docs.github.com/actions](https://docs.github.com/en/actions) |
| **Python CI** | Guide spÃ©cifique Python | [docs.github.com/actions/python](https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-python) |

### Exemple de workflow CI

```yaml
# .github/workflows/ci.yml
name: CI

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Run tests
        run: pytest
```

---

## 7. ğŸ“– Concepts ComplÃ©mentaires

### SimilaritÃ© cosinus

La similaritÃ© cosinus mesure l'angle entre deux vecteurs. Plus l'angle est petit, plus les vecteurs sont similaires.

**Formule** : `cos(Î¸) = (A Â· B) / (||A|| Ã— ||B||)`

- RÃ©sultat entre -1 et 1
- 1 = identiques
- 0 = orthogonaux (pas de relation)
- -1 = opposÃ©s

**Ressource** : [Wikipedia - Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity)

### OpenAPI / Swagger

Standard de documentation pour APIs REST. FastAPI gÃ©nÃ¨re automatiquement la documentation OpenAPI.

**Ressource** : [swagger.io/specification](https://swagger.io/specification/)

### Embeddings et NLP

**Ressource** : [HuggingFace NLP Course - Chapter 1](https://huggingface.co/learn/nlp-course/chapter1/1)

---

## ğŸ”— RÃ©capitulatif des liens essentiels

### Incontournables (Ã  consulter en prioritÃ©)

1. [AWS - What is RAG?](https://aws.amazon.com/what-is/retrieval-augmented-generation/)
2. [SBERT - Semantic Search](https://www.sbert.net/examples/sentence_transformer/applications/semantic-search/README.html)
3. [HuggingFace - Question Answering](https://huggingface.co/tasks/question-answering)
4. [FastAPI - Tutorial](https://fastapi.tiangolo.com/tutorial/)
5. [HuggingFace - Inference API](https://huggingface.co/docs/api-inference/index)

### ModÃ¨les Ã  utiliser

| Usage | ModÃ¨le | Lien |
|-------|--------|------|
| Embeddings | all-MiniLM-L6-v2 | [Model Card](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) |
| LLM | Mistral-7B-Instruct-v0.2 | [Model Card](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2) |
| Q&A Extractif | roberta-base-squad2 | [Model Card](https://huggingface.co/deepset/roberta-base-squad2) |

---

## ğŸ’¡ Conseils de lecture

1. **Ne lisez pas tout d'un coup** : Consultez les ressources au fur et Ã  mesure de votre avancement
2. **Testez le code** : Chaque exemple de code est fonctionnel, testez-le !
3. **Utilisez les dÃ©mos HuggingFace** : Les pages de modÃ¨les ont des interfaces de test
4. **Documentez vos dÃ©couvertes** : Notez ce qui vous a aidÃ© pour votre rapport de veille

---

*DerniÃ¨re mise Ã  jour : Janvier 2026*